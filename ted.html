<!DOCTYPE html>

<html lang="en">

 	<head>
		<title>Tensorflow</title>
		<link href="ted.css" rel="stylesheet">
	</head>

	<p>
		Jian Hong Li, Harry Zhu
		Period 8
	</p>

  <h1>
    Neural Network
  </h1>
    <img src="https://www.ibm.com/content/dam/connectedassets-adobe-cms/worldwide-content/cdp/cf/ul/g/3a/b8/ICLH_Diagram_Batch_01_03-DeepNeuralNetwork.component.simple-narrative-xl.ts=1679336162077.png/content/adobe-cms/us/en/topics/neural-networks/jcr:content/root/table_of_contents/intro/simple_narrative/image" alt="Neural Networks">

  <p>
    The way our brain learn is through experiencing many different possiblities.
    After experiencing an event, our brain will deem it either a failure that should
    discarded or a success that should be kept. These networks represent all the possibility that could occur.
    In machine learning, these networks are simply mathematical operations. An given input of
    data will run through many, many different networks of training, creating a bunch of possibility. <thead>
    job of the of AI is to decide which one of these new datas are worth keeping.
  </p>

  <h1>
    Application of Tensorflow
  </h1>

  <p>

  </p>

  <h1>
    Gradient
  </h1>

  <img src="https://www.google.com/url?sa=i&url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FFile%3AGradient_vectors_on_cos%2528x%2529*cos%2528y%2529.png&psig=AOvVaw2eC2B8OKi-TnY1TfKNIKsV&ust=1680658828282000&source=images&cd=vfe&ved=0CAwQjRxqFwoTCKCl2pqMj_4CFQAAAAAdAAAAABAD" alt="Neural Networks">
  <p>
    Gradient is the cornerstone to any machine learning system. If you have taken multivariable calculus or linear algebra you will probably be familiar with this term.
    But for those that dont, gradient is like a function that takes in an input and returns a vector that points at the largest ascent.
    In this 3D graph, imagine the curve being our data plotted. We can take the gradient and find the largest ascend as shown by the arrows. Machine learning uses gradient descent which is basically this arrow but pointing at the opposite direction
    The other graph is a contour map of a similar curve to the first graph, think of an upside down umbrella.
    Why are gradients important for machine learning you may ask. Gradient points toward the highest increase given a function or data, and what machine learning wants is to find a way to optimize these data points. By know where the largest increase, or in our case the largest decrease is at, we could find out how to optimize our data the best. Tensorflow provides methods that do the gradient calculation for you
  </p>



</html>
